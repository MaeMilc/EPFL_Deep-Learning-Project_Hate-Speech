{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Leaning Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T08:42:01.948253Z",
          "iopub.status.busy": "2024-03-13T08:42:01.946314Z",
          "iopub.status.idle": "2024-03-13T08:42:04.865056Z",
          "shell.execute_reply": "2024-03-13T08:42:04.864006Z",
          "shell.execute_reply.started": "2024-03-13T08:42:01.948171Z"
        },
        "id": "E_8PRTZ0V0FH",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libretranslatepy in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (4.38.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m894.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m894.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m941.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
            "Collecting pyarrow>=12.0.0\n",
            "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow-hotfix\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: pandas in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /home/moe/anaconda3/envs/iml_project/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, yarl, responses, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.9.4 aiosignal-1.3.1 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-15.0.2 pyarrow-hotfix-0.6 responses-0.18.0 xxhash-3.4.1 yarl-1.9.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install libretranslatepy\n",
        "%pip install transformers datasets evaluate\n",
        "\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.utils as utils\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import requests\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run libretranslate on http://127.0.0.1:5000**\n",
        "\n",
        "*Add the languages to translate in --load-only <comma-separated language codes> Set available languages (ar,de,en,es,fr,ga,hi,it,ja,ko,pt,ru,zh)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Jupyter does not allow the process to run in the background, thus start a console and run libretranslate --load-only en,de**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Add the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-13T08:42:04.914077Z",
          "iopub.status.busy": "2024-03-13T08:42:04.913030Z",
          "iopub.status.idle": "2024-03-13T08:42:07.083537Z",
          "shell.execute_reply": "2024-03-13T08:42:07.082538Z",
          "shell.execute_reply.started": "2024-03-13T08:42:04.913976Z"
        },
        "id": "D5Vv-3jyEly3",
        "outputId": "5d7acea3-03aa-4d0a-b25c-8bc858515942",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:42<00:00, 3974169.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "transforms_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Loading the CIFAR-10 dataset:\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Iterate through the dataset and translate, specifiy the source and target language. For batch processing, add multiple requests into the array*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Hallo, wie geht's?\", 'Wie heißt du?']\n"
          ]
        }
      ],
      "source": [
        "url = \"http://127.0.0.1:5000/translate\"\n",
        "\n",
        "params = {\"q\" : [\"Hello, how are you?\", \"What is your name?\"],\n",
        "          \"source\" : \"en\",\n",
        "          \"target\" : \"de\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    translated_text = response.json()[\"translatedText\"]\n",
        "    print(translated_text)\n",
        "else:\n",
        "    print(f\"Request failed with status code {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dUdYGXaRJFC"
      },
      "source": [
        "**Load the pretrained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-13T08:42:24.235718Z",
          "iopub.status.busy": "2024-03-13T08:42:24.234988Z",
          "iopub.status.idle": "2024-03-13T08:43:40.778094Z",
          "shell.execute_reply": "2024-03-13T08:43:40.200038Z",
          "shell.execute_reply.started": "2024-03-13T08:42:24.235653Z"
        },
        "id": "ME6e6Mh7EvMB",
        "outputId": "6b40f2f2-77f0-4f31-f20e-ee0c9684c1b3",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69deb8a854914e1abd7dc712d46500a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d19d5ba3f6d4cc4a7eba060eae4ead1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "model_bert_l4 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google/bert_uncased_L-4_H-128_A-2\", num_labels=2, id2label=id2label, label2id=label2id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Create a Dataloader for training and test datasets*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset, shuffle=True, batch_size=10)\n",
        "eval_dataloader = DataLoader(dataset, batch_size=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
